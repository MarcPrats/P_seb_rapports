%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%       Microscopic analysis of load curve      %
%   Xavier                                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Microscopic analysis of load curve}
%Xavier
The sampling frequency used in the case of a microscopic analysis of the load curve is between 5 and 10k$Hz$. Such a frequency allows to access to the transient response of devices. That high sampling frequency enables to avoid a difficulty encountered in macroscopic analysis, which flows from the fact that an appliance is generally switched on while other appliance are already in use. 
\\

An important point to notice is that the transient response is linked with the physical role of the device. Studies have then been conducted to isolate characteristic parameters of the appliance from the transient response. Here is an example of a transient response :
\\
% Figure





[1] address the problem of classification of transient signals which are modelled as a Smooth transition autoregressive model. Figure x shows some abrupt transitions on the transient signal, which are called breakpoints. Let $K$ denote the number of breakpoints, and $\underline{\tau} = [\tau_1,...,\tau_K]$ denote the sequence of the $K$ breakpoints. By convention, $[\tau_0;\tau_{K+1}]$ represents the observation interval of the signal. 
\\

 Therefore, the signal is modelled as a linear combination of regression function $\{m_k\}_{k\in{1,K+1}}$.~$m_k$ is the regression model of the signal over the segment $[\tau_{k-1};\tau_{k}]$. Then, the signal is expressed as

\begin{equation}
\forall t\in [\tau_0;\tau_{K+1}],m(t)= \sum_{k=1}^{K+1}p_k(t)m_k(t)
\end{equation}

where $p_k(t)$ is the weight function of the $k^{th}$ regression model which can be expressed as follow
\begin{equation}
\forall k\in [1,K+1], p_k(t)= \pi_{\eta_{k-1}}(t-\tau_{k-1})-\pi_{\eta_{k}}(t-\tau_{k})
\end{equation}

$\pi_{\eta_{k}}$ is the transition function of the $k^{th}$ breakpoint, which depends on a vector of parameter $\eta_{k}$. In the model described in [1], $\pi_{\eta_{k}}$ is a sigmoide function, whose expression is 
\begin{equation}
\pi_{\eta_{k}} = \frac{1}{1+exp(\frac{t}{\lambda_k})}
\end{equation}

The only element in $\eta_{k}$ is then $\lambda_k$, which is a scale parameter. Let $\underline{\lambda}$ denote the concatenation of all the scale parameters $\underline{\lambda} = [\lambda_1,...,\lambda_K]$.
\\

 Regression model are considered in [1] as polynomial 

\begin{equation}
m_k(t)= \sum_{q=0}^{Q_k} \beta^{(q)} _kt^q
\end{equation}

$\beta^{(q)} _k$ is the $q^{th}$ order regression coefficient of the $k^{th}$ regression model, and $Q_k$ is the order of $m_k(t)$. POUR YO : j'aimerais dire un truc style let beta denote the concatenation of ... et la meme chose pour Q (former des vecteurs concatenant les differentes valeurs de ces deux parametres) mais j'ai deja utilise cette tournure au moins une fois. Tu aurais des idees ? :D
\\

A common model for the observed signal is 


\begin{equation}
s(t)=m(t) + \epsilon (t)
\end{equation}

$\epsilon (t)$ is an additive white Gaussian noise whose variance is $\sigma^2$. The different parameters which have to be evaluated are then :
\begin{equation}
\theta=\{\underline{\lambda},\underline{\tau},\underline{\beta},\underline{Q},\sigma ^2,K\}
\end{equation}
\\

The approach presented in [1] is a Bayesian one. The $a$ $posteriori$ probability density function of $\theta$ is obtained thanks to Bayes formula. The algorithm used to sample the distibution is a Reversible Jump Markov chain Monte Carlo (RJMCMC). The algorithm consisted in a main loop. Each time th algorithm